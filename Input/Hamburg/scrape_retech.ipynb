{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a353b66",
   "metadata": {},
   "source": [
    "# RETech Mitglieder – Partner-Links extrahieren\n",
    "\n",
    "Dieses Notebook lädt die Mitglieder-Seite von RETech, extrahiert pro Karte den Namen und den externen Link (\"Zur Website\") und speichert die Ergebnisse als CSV.\n",
    "\n",
    "- Quelle: https://retech-germany.net/mitglieder/\n",
    "- Ausgabe: data/retech_mitglieder.csv\n",
    "\n",
    "Hinweise:\n",
    "- Die Seite lädt visuell weitere Karten beim Scrollen. Wir umgehen dies, indem wir zusätzlich auf mögliche Folgeseiten (page/2, page/3, …) prüfen und alle gefundenen Karten zusammensetzen. Falls die Seite serverseitig bereits alle Karten liefert, reicht ein Request.\n",
    "- Aus jedem Kartenblock wird der Name aus der nächstgelegenen Überschrift (H2/H3/H4) extrahiert, der externe Link über die Schaltfläche \"Zur Website\". Interne Navigations-Links (retech-germany.net) sowie Social-Profile werden gefiltert.\n",
    "- Doppelte Einträge werden dedupliziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f08d96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 65 entries to data/retech_mitglieder.csv\n",
      "category\n",
      "mitglieder    65\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>website_url</th>\n",
       "      <th>retech_profile_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>ABC Circular</td>\n",
       "      <td>https://www.ab-circular.de</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>BC Berlin Consult GmbH</td>\n",
       "      <td>https://www.berlin-consult.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>BN Umwelt GmbH</td>\n",
       "      <td>https://bn-umwelt.sh/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Bergischer Abfallwirtschaftsverband</td>\n",
       "      <td>https://www.bavweb.de/Bergischer-Abfallwirtsch...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Berliner Stadtreinigungsbetriebe (BSR)</td>\n",
       "      <td>https://www.bsr.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Berliner Stadtreinigungsbetriebe (BSR)</td>\n",
       "      <td>https://www.dbfz.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>BlackForest Solutions GmbH</td>\n",
       "      <td>https://www.blackforest-solutions.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Bondacon International</td>\n",
       "      <td>https://www.bondacon.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>COMMIT Project Partners GmbH</td>\n",
       "      <td>https://commit-group.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Compost Systems GmbH</td>\n",
       "      <td>https://www.compost-systems.com/de</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>DPG Deutsche Pfandsystem GmbH</td>\n",
       "      <td>https://dpg-pfandsystem.de/index.php/de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Doppstadt Umwelttechnik GmbH</td>\n",
       "      <td>https://www.doppstadt.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>ECOLOGICON GmbH</td>\n",
       "      <td>https://ecologicon.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>EEW Energy from Waste GmbH</td>\n",
       "      <td>https://www.eew-energyfromwaste.com/de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>ESE GmbH</td>\n",
       "      <td>https://www.ese.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>EUWELLE Environmental Technology GmbH</td>\n",
       "      <td>https://www.euwelle.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Eggersmann GmbH</td>\n",
       "      <td>https://www.eggersmann-recyclingtechnology.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>FAUN Umwelttechnik GmbH &amp; Co. KG</td>\n",
       "      <td>https://www.faun.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Filters</td>\n",
       "      <td>https://steinertglobal.com/de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Filters</td>\n",
       "      <td>https://www.ab-circular.de</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                    name  \\\n",
       "0   mitglieder                            ABC Circular   \n",
       "1   mitglieder                  BC Berlin Consult GmbH   \n",
       "2   mitglieder                          BN Umwelt GmbH   \n",
       "3   mitglieder     Bergischer Abfallwirtschaftsverband   \n",
       "4   mitglieder  Berliner Stadtreinigungsbetriebe (BSR)   \n",
       "5   mitglieder  Berliner Stadtreinigungsbetriebe (BSR)   \n",
       "6   mitglieder              BlackForest Solutions GmbH   \n",
       "7   mitglieder                  Bondacon International   \n",
       "8   mitglieder            COMMIT Project Partners GmbH   \n",
       "9   mitglieder                    Compost Systems GmbH   \n",
       "10  mitglieder           DPG Deutsche Pfandsystem GmbH   \n",
       "11  mitglieder            Doppstadt Umwelttechnik GmbH   \n",
       "12  mitglieder                         ECOLOGICON GmbH   \n",
       "13  mitglieder              EEW Energy from Waste GmbH   \n",
       "14  mitglieder                                ESE GmbH   \n",
       "15  mitglieder   EUWELLE Environmental Technology GmbH   \n",
       "16  mitglieder                         Eggersmann GmbH   \n",
       "17  mitglieder        FAUN Umwelttechnik GmbH & Co. KG   \n",
       "18  mitglieder                                 Filters   \n",
       "19  mitglieder                                 Filters   \n",
       "\n",
       "                                          website_url retech_profile_url  \n",
       "0                          https://www.ab-circular.de               None  \n",
       "1                      https://www.berlin-consult.de/               None  \n",
       "2                               https://bn-umwelt.sh/               None  \n",
       "3   https://www.bavweb.de/Bergischer-Abfallwirtsch...               None  \n",
       "4                                 https://www.bsr.de/               None  \n",
       "5                                https://www.dbfz.de/               None  \n",
       "6              https://www.blackforest-solutions.com/               None  \n",
       "7                           https://www.bondacon.com/               None  \n",
       "8                           https://commit-group.com/               None  \n",
       "9                  https://www.compost-systems.com/de               None  \n",
       "10           https://dpg-pfandsystem.de/index.php/de/               None  \n",
       "11                          https://www.doppstadt.de/               None  \n",
       "12                            https://ecologicon.com/               None  \n",
       "13            https://www.eew-energyfromwaste.com/de/               None  \n",
       "14                               https://www.ese.com/               None  \n",
       "15                            https://www.euwelle.de/               None  \n",
       "16    https://www.eggersmann-recyclingtechnology.com/               None  \n",
       "17                              https://www.faun.com/               None  \n",
       "18                     https://steinertglobal.com/de/               None  \n",
       "19                         https://www.ab-circular.de               None  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pathlib\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://retech-germany.net/mitglieder/\"\n",
    "OUTPUT_DIR = pathlib.Path(\"data\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_FILE = OUTPUT_DIR / \"retech_mitglieder.csv\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "}\n",
    "\n",
    "# session with headers\n",
    "session = requests.Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "SOCIAL_DOMAINS = {\n",
    "    \"linkedin.com\", \"facebook.com\", \"twitter.com\", \"x.com\", \"youtube.com\", \"instagram.com\",\n",
    "    \"xing.com\", \"kununu.com\", \"google.com\", \"goo.gl\", \"bit.ly\", \"t.me\"\n",
    "}\n",
    "WEBSITE_TOKENS = [\"zur website\", \"website\", \"webseite\", \"homepage\", \"mehr erfahren\", \"mehr infos\"]\n",
    "IGNORED_HEADING_TOKENS = {\n",
    "    \"retech\", \"mitglieder\", \"jetzt\", \"kontakt\", \"additional\", \"links\",\n",
    "    \"tätigkeitsbereich\", \"wertschöpfungskettenbereich\", \"forschung\", \"entwicklung\",\n",
    "    \"beratung\", \"planung\", \"logistik\", \"management\", \"rechtlicher\", \"rahmen\", \"epr\",\n",
    "    \"maschinen\", \"anlagenbau\", \"abfallmanagement\", \"markterweiterung\", \"exportförderung\",\n",
    "    \"sonstiges\"\n",
    "}\n",
    "\n",
    "\n",
    "def clean_text(s: str | None) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def normalize_url(u: str | None) -> str | None:\n",
    "    if not u:\n",
    "        return None\n",
    "    u = u.strip()\n",
    "    # Fix double schemes like https://https://...\n",
    "    u = re.sub(r\"^(https?://)+\", \"https://\", u, flags=re.I)\n",
    "    # Add scheme if missing\n",
    "    if not re.match(r\"^https?://\", u, re.I):\n",
    "        if u.startswith(\"//\"):\n",
    "            u = \"https:\" + u\n",
    "        else:\n",
    "            u = \"https://\" + u.lstrip(\"/\")\n",
    "    return u\n",
    "\n",
    "\n",
    "def is_social_url(url: str) -> bool:\n",
    "    host = urlparse(url).netloc.lower()\n",
    "    return any(dom in host for dom in SOCIAL_DOMAINS)\n",
    "\n",
    "\n",
    "def is_external(url: str) -> bool:\n",
    "    p = urlparse(url)\n",
    "    return bool(p.scheme and p.netloc) and 'retech-germany.net' not in p.netloc.lower()\n",
    "\n",
    "\n",
    "def normalize_company_name(name: str | None) -> str | None:\n",
    "    if not name:\n",
    "        return None\n",
    "    n = clean_text(name)\n",
    "    # Strip common company suffixes for matching\n",
    "    n = re.sub(r\"\\b(gmbh & co\\.? kg|gmbh & co|gmbh|ag|kg|ug|e\\.v\\.|e\\.v|ev|mbh)\\b\", \"\", n, flags=re.I)\n",
    "    return clean_text(n)\n",
    "\n",
    "\n",
    "def nearest_heading_in_ancestors(node) -> str | None:\n",
    "    # Prefer headings inside ancestor containers; choose the longest reasonable one, skipping ignored tokens\n",
    "    cur = node\n",
    "    for _ in range(7):\n",
    "        if cur is None:\n",
    "            break\n",
    "        if hasattr(cur, 'find_all'):\n",
    "            heads = cur.find_all(['h2','h3','h4'])\n",
    "            if heads:\n",
    "                # Choose heading with max text length after filtering\n",
    "                candidates = []\n",
    "                for h in heads:\n",
    "                    t = clean_text(h.get_text())\n",
    "                    low = t.lower()\n",
    "                    if not t:\n",
    "                        continue\n",
    "                    # Skip generic taxonomy headings\n",
    "                    if any(tok in low for tok in IGNORED_HEADING_TOKENS):\n",
    "                        continue\n",
    "                    candidates.append(t)\n",
    "                if candidates:\n",
    "                    return max(candidates, key=len)\n",
    "        cur = cur.parent\n",
    "    return None\n",
    "\n",
    "\n",
    "def nearest_heading_text(node) -> str | None:\n",
    "    # First try ancestor-based search\n",
    "    t = nearest_heading_in_ancestors(node)\n",
    "    if t:\n",
    "        return t\n",
    "    # Fallback: walk backwards but skip generic taxonomy headings\n",
    "    for prev in node.previous_elements:\n",
    "        name = getattr(prev, 'name', None)\n",
    "        if name in ('h2','h3','h4'):\n",
    "            txt = clean_text(prev.get_text())\n",
    "            if txt and not any(tok in txt.lower() for tok in IGNORED_HEADING_TOKENS):\n",
    "                return txt\n",
    "    return None\n",
    "\n",
    "\n",
    "def score_anchor(a, base_url: str, name_hint: str | None = None) -> tuple[int, str]:\n",
    "    href = a.get('href') or ''\n",
    "    u = normalize_url(urljoin(base_url, href))\n",
    "    if not u:\n",
    "        return (-1, '')\n",
    "    if not is_external(u) or is_social_url(u):\n",
    "        return (-1, u)\n",
    "    label = clean_text(a.get_text()).lower()\n",
    "    score = 0\n",
    "    if any(tok in label for tok in WEBSITE_TOKENS):\n",
    "        score += 4\n",
    "    # Favor domains\n",
    "    if re.search(r\"([a-z0-9-]+\\.)+[a-z]{2,}\", u, re.I):\n",
    "        score += 2\n",
    "    # Attributes\n",
    "    if a.get('rel') and ('external' in ' '.join(a.get('rel')).lower()):\n",
    "        score += 1\n",
    "    if a.get('target') == '_blank':\n",
    "        score += 1\n",
    "    # If company token appears in domain, boost strongly\n",
    "    if name_hint:\n",
    "        nh = normalize_company_name(name_hint).lower()\n",
    "        host = urlparse(u).netloc.lower()\n",
    "        sld = host.split('.')[-2] if '.' in host else host\n",
    "        if sld and sld in nh:\n",
    "            score += 4\n",
    "    return (score, u)\n",
    "\n",
    "\n",
    "def find_card_container_for_heading(h):\n",
    "    parent = h\n",
    "    for _ in range(7):\n",
    "        if parent is None:\n",
    "            break\n",
    "        if hasattr(parent, 'find_all'):\n",
    "            links = parent.find_all('a', href=True)\n",
    "            if len(links) >= 1:\n",
    "                return parent\n",
    "        parent = parent.parent\n",
    "    return h.parent if h else None\n",
    "\n",
    "\n",
    "def extract_from_headings(soup: BeautifulSoup) -> list[dict]:\n",
    "    rows: list[dict] = []\n",
    "    seen: set[tuple[str, str]] = set()\n",
    "    for h in soup.find_all(['h2','h3','h4']):\n",
    "        name = clean_text(h.get_text())\n",
    "        if not name or len(name) < 2 or len(name) > 200:\n",
    "            continue\n",
    "        low = name.lower()\n",
    "        if any(t in low for t in IGNORED_HEADING_TOKENS):\n",
    "            continue\n",
    "        container = find_card_container_for_heading(h)\n",
    "        if not container:\n",
    "            continue\n",
    "        candidates = []\n",
    "        for a in container.find_all('a', href=True):\n",
    "            sc, u = score_anchor(a, BASE_URL, name_hint=name)\n",
    "            if sc >= 0:\n",
    "                candidates.append((sc, u))\n",
    "        # Look in a few following siblings as fallback\n",
    "        if not candidates:\n",
    "            sib_limit = 0\n",
    "            for sib in h.next_siblings:\n",
    "                if sib_limit > 10:\n",
    "                    break\n",
    "                sib_limit += 1\n",
    "                if getattr(sib, 'find_all', None):\n",
    "                    for a in sib.find_all('a', href=True):\n",
    "                        sc, u = score_anchor(a, BASE_URL, name_hint=name)\n",
    "                        if sc >= 0:\n",
    "                            candidates.append((sc, u))\n",
    "        if not candidates:\n",
    "            continue\n",
    "        candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_url = candidates[0][1]\n",
    "        key = (name, top_url)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        rows.append({\n",
    "            'category': 'mitglieder',\n",
    "            'name': name,\n",
    "            'website_url': top_url,\n",
    "            'retech_profile_url': None,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "\n",
    "def extract_cards_from_soup(soup: BeautifulSoup) -> list[dict]:\n",
    "    rows: list[dict] = []\n",
    "    seen: set[tuple[str, str]] = set()\n",
    "    for a in soup.select('a[href]'):\n",
    "        sc, u = score_anchor(a, BASE_URL)\n",
    "        if sc < 0:\n",
    "            continue\n",
    "        name = nearest_heading_text(a)\n",
    "        if not name:\n",
    "            domain = urlparse(u).netloc or u\n",
    "            name = re.sub(r'^www\\.', '', domain)\n",
    "        # Filter taxonomy names accidentally captured\n",
    "        if any(tok in name.lower() for tok in IGNORED_HEADING_TOKENS):\n",
    "            continue\n",
    "        key = (name, u)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        rows.append({\n",
    "            'category': 'mitglieder',\n",
    "            'name': name,\n",
    "            'website_url': u,\n",
    "            'retech_profile_url': None,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "\n",
    "def merge_rows(primary: list[dict], secondary: list[dict]) -> list[dict]:\n",
    "    out: list[dict] = []\n",
    "    seen: set[tuple[str, str]] = set()\n",
    "    for src in (primary, secondary):\n",
    "        for r in src:\n",
    "            key = (r.get('name'), r.get('website_url'))\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "            out.append(r)\n",
    "    return out\n",
    "\n",
    "\n",
    "def fetch_all_members() -> list[dict]:\n",
    "    rows: list[dict] = []\n",
    "    # 1) Hauptseite\n",
    "    r = session.get(BASE_URL, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    rows = merge_rows(extract_from_headings(soup), extract_cards_from_soup(soup))\n",
    "\n",
    "    # 2) WordPress-typische Pagination /page/2, ...\n",
    "    seen_before = {(d['name'], d['website_url']) for d in rows}\n",
    "    for i in range(2, 21):\n",
    "        page_url = urljoin(BASE_URL, f'page/{i}/')\n",
    "        try:\n",
    "            rp = session.get(page_url, timeout=20)\n",
    "            if rp.status_code == 404 or len(rp.text) < 2000:\n",
    "                break\n",
    "            psoup = BeautifulSoup(rp.text, 'lxml')\n",
    "            new_rows = merge_rows(extract_from_headings(psoup), extract_cards_from_soup(psoup))\n",
    "            added = 0\n",
    "            for row in new_rows:\n",
    "                key = (row['name'], row['website_url'])\n",
    "                if key not in seen_before:\n",
    "                    rows.append(row)\n",
    "                    seen_before.add(key)\n",
    "                    added += 1\n",
    "            if added == 0:\n",
    "                break\n",
    "            time.sleep(0.2)\n",
    "        except requests.RequestException:\n",
    "            break\n",
    "    return rows\n",
    "\n",
    "\n",
    "rows = fetch_all_members()\n",
    "df = pd.DataFrame(rows) if rows else pd.DataFrame(columns=['category','name','website_url','retech_profile_url'])\n",
    "\n",
    "# Aufbereiten, sortieren, speichern\n",
    "# Normalize URLs (fix any leftover duplicates)\n",
    "df['website_url'] = df['website_url'].apply(normalize_url)\n",
    "df['name'] = df['name'].fillna('').apply(clean_text).replace({'': None})\n",
    "# Drop rows with missing or obviously malformed URLs\n",
    "mask_valid = df['website_url'].fillna('').str.match(r'^https?://', case=False)\n",
    "df = df[mask_valid]\n",
    "\n",
    "df = df.drop_duplicates(subset=['name','website_url']).sort_values(by=['category','name','website_url'], na_position='last').reset_index(drop=True)\n",
    "\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f'Saved {len(df)} entries to {OUTPUT_FILE}')\n",
    "try:\n",
    "    print(df['category'].value_counts(dropna=False))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27e60c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>website_url</th>\n",
       "      <th>retech_profile_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Ramboll Deutschland GmbH</td>\n",
       "      <td>https://www.ramboll.com/de-de</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>SSI SCHÄFER Plastics GmbH</td>\n",
       "      <td>https://ssi-plastic.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>STEINERT GmbH</td>\n",
       "      <td>https://steinertglobal.com/de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Stadtreinigung Hamburg</td>\n",
       "      <td>https://www.stadtreinigung.hamburg/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Sutco RecyclingTechnik GmbH</td>\n",
       "      <td>https://www.sutco.com</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>TU Dresden – Institut für Abfall- und Kreislau...</td>\n",
       "      <td>https://tu-dresden.de/bu/umwelt/hydro/iak</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>TU Dresden – Institut für Abfall- und Kreislau...</td>\n",
       "      <td>https://weima.com/de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Tietjen Verfahrenstechnik GmbH</td>\n",
       "      <td>https://www.tietjen-original.com</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Universität Rostock</td>\n",
       "      <td>https://www.auf.uni-rostock.de/professuren/bau...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Vecoplan AG</td>\n",
       "      <td>https://vecoplan.com/de</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Wehrle-Werk AG</td>\n",
       "      <td>https://www.wehrle-werk.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>adelphi consult GmbH</td>\n",
       "      <td>https://adelphi.de/de</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>cyclos GmbH</td>\n",
       "      <td>https://cyclos.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>eclareon GmbH</td>\n",
       "      <td>https://www.eclareon.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>econ industries</td>\n",
       "      <td>https://www.econindustries.com/de</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>econAN international GmbH</td>\n",
       "      <td>https://www.doppstadt.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>energiewaechter GmbH</td>\n",
       "      <td>https://www.energiewaechter.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>enviacon GmbH</td>\n",
       "      <td>https://www.enviacon.com/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>mele Biogas GmbH</td>\n",
       "      <td>https://mele.de/energie-umwelt/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>umwelttechnik &amp; ingenieure GmbH</td>\n",
       "      <td>https://www.uigmbh.de/</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                               name  \\\n",
       "45  mitglieder                           Ramboll Deutschland GmbH   \n",
       "46  mitglieder                          SSI SCHÄFER Plastics GmbH   \n",
       "47  mitglieder                                      STEINERT GmbH   \n",
       "48  mitglieder                             Stadtreinigung Hamburg   \n",
       "49  mitglieder                        Sutco RecyclingTechnik GmbH   \n",
       "50  mitglieder  TU Dresden – Institut für Abfall- und Kreislau...   \n",
       "51  mitglieder  TU Dresden – Institut für Abfall- und Kreislau...   \n",
       "52  mitglieder                     Tietjen Verfahrenstechnik GmbH   \n",
       "53  mitglieder                                Universität Rostock   \n",
       "54  mitglieder                                        Vecoplan AG   \n",
       "55  mitglieder                                     Wehrle-Werk AG   \n",
       "56  mitglieder                               adelphi consult GmbH   \n",
       "57  mitglieder                                        cyclos GmbH   \n",
       "58  mitglieder                                      eclareon GmbH   \n",
       "59  mitglieder                                    econ industries   \n",
       "60  mitglieder                          econAN international GmbH   \n",
       "61  mitglieder                               energiewaechter GmbH   \n",
       "62  mitglieder                                      enviacon GmbH   \n",
       "63  mitglieder                                   mele Biogas GmbH   \n",
       "64  mitglieder                    umwelttechnik & ingenieure GmbH   \n",
       "\n",
       "                                          website_url retech_profile_url  \n",
       "45                      https://www.ramboll.com/de-de               None  \n",
       "46                           https://ssi-plastic.com/               None  \n",
       "47                     https://steinertglobal.com/de/               None  \n",
       "48                https://www.stadtreinigung.hamburg/               None  \n",
       "49                              https://www.sutco.com               None  \n",
       "50          https://tu-dresden.de/bu/umwelt/hydro/iak               None  \n",
       "51                              https://weima.com/de/               None  \n",
       "52                   https://www.tietjen-original.com               None  \n",
       "53  https://www.auf.uni-rostock.de/professuren/bau...               None  \n",
       "54                            https://vecoplan.com/de               None  \n",
       "55                        https://www.wehrle-werk.de/               None  \n",
       "56                              https://adelphi.de/de               None  \n",
       "57                                 https://cyclos.de/               None  \n",
       "58                          https://www.eclareon.com/               None  \n",
       "59                  https://www.econindustries.com/de               None  \n",
       "60                          https://www.doppstadt.de/               None  \n",
       "61                    https://www.energiewaechter.de/               None  \n",
       "62                          https://www.enviacon.com/               None  \n",
       "63                    https://mele.de/energie-umwelt/               None  \n",
       "64                             https://www.uigmbh.de/               None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ba3f9",
   "metadata": {},
   "source": [
    "# Kombiniere Daten in ein Standardformat\n",
    "\n",
    "Wie im BDE-Notebook führen wir ein vereinheitlichtes Schema ein: `section, name, url, profile_url, source_page` und speichern es unter `data/retech_scrape.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1ab2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 65 combined rows to data/retech_scrape.csv\n",
      "source_page  section   \n",
      "mitglieder   mitglieder    65\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>profile_url</th>\n",
       "      <th>source_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>ABC Circular</td>\n",
       "      <td>https://www.ab-circular.de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>BC Berlin Consult GmbH</td>\n",
       "      <td>https://www.berlin-consult.de/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>BN Umwelt GmbH</td>\n",
       "      <td>https://bn-umwelt.sh/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Bergischer Abfallwirtschaftsverband</td>\n",
       "      <td>https://www.bavweb.de/Bergischer-Abfallwirtsch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Berliner Stadtreinigungsbetriebe (BSR)</td>\n",
       "      <td>https://www.bsr.de/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Berliner Stadtreinigungsbetriebe (BSR)</td>\n",
       "      <td>https://www.dbfz.de/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>BlackForest Solutions GmbH</td>\n",
       "      <td>https://www.blackforest-solutions.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Bondacon International</td>\n",
       "      <td>https://www.bondacon.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>COMMIT Project Partners GmbH</td>\n",
       "      <td>https://commit-group.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Compost Systems GmbH</td>\n",
       "      <td>https://www.compost-systems.com/de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>DPG Deutsche Pfandsystem GmbH</td>\n",
       "      <td>https://dpg-pfandsystem.de/index.php/de/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Doppstadt Umwelttechnik GmbH</td>\n",
       "      <td>https://www.doppstadt.de/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>ECOLOGICON GmbH</td>\n",
       "      <td>https://ecologicon.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>EEW Energy from Waste GmbH</td>\n",
       "      <td>https://www.eew-energyfromwaste.com/de/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>ESE GmbH</td>\n",
       "      <td>https://www.ese.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>EUWELLE Environmental Technology GmbH</td>\n",
       "      <td>https://www.euwelle.de/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Eggersmann GmbH</td>\n",
       "      <td>https://www.eggersmann-recyclingtechnology.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>FAUN Umwelttechnik GmbH &amp; Co. KG</td>\n",
       "      <td>https://www.faun.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Filters</td>\n",
       "      <td>https://steinertglobal.com/de/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mitglieder</td>\n",
       "      <td>Filters</td>\n",
       "      <td>https://www.ab-circular.de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mitglieder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       section                                    name  \\\n",
       "0   mitglieder                            ABC Circular   \n",
       "1   mitglieder                  BC Berlin Consult GmbH   \n",
       "2   mitglieder                          BN Umwelt GmbH   \n",
       "3   mitglieder     Bergischer Abfallwirtschaftsverband   \n",
       "4   mitglieder  Berliner Stadtreinigungsbetriebe (BSR)   \n",
       "5   mitglieder  Berliner Stadtreinigungsbetriebe (BSR)   \n",
       "6   mitglieder              BlackForest Solutions GmbH   \n",
       "7   mitglieder                  Bondacon International   \n",
       "8   mitglieder            COMMIT Project Partners GmbH   \n",
       "9   mitglieder                    Compost Systems GmbH   \n",
       "10  mitglieder           DPG Deutsche Pfandsystem GmbH   \n",
       "11  mitglieder            Doppstadt Umwelttechnik GmbH   \n",
       "12  mitglieder                         ECOLOGICON GmbH   \n",
       "13  mitglieder              EEW Energy from Waste GmbH   \n",
       "14  mitglieder                                ESE GmbH   \n",
       "15  mitglieder   EUWELLE Environmental Technology GmbH   \n",
       "16  mitglieder                         Eggersmann GmbH   \n",
       "17  mitglieder        FAUN Umwelttechnik GmbH & Co. KG   \n",
       "18  mitglieder                                 Filters   \n",
       "19  mitglieder                                 Filters   \n",
       "\n",
       "                                                  url  profile_url source_page  \n",
       "0                          https://www.ab-circular.de          NaN  mitglieder  \n",
       "1                      https://www.berlin-consult.de/          NaN  mitglieder  \n",
       "2                               https://bn-umwelt.sh/          NaN  mitglieder  \n",
       "3   https://www.bavweb.de/Bergischer-Abfallwirtsch...          NaN  mitglieder  \n",
       "4                                 https://www.bsr.de/          NaN  mitglieder  \n",
       "5                                https://www.dbfz.de/          NaN  mitglieder  \n",
       "6              https://www.blackforest-solutions.com/          NaN  mitglieder  \n",
       "7                           https://www.bondacon.com/          NaN  mitglieder  \n",
       "8                           https://commit-group.com/          NaN  mitglieder  \n",
       "9                  https://www.compost-systems.com/de          NaN  mitglieder  \n",
       "10           https://dpg-pfandsystem.de/index.php/de/          NaN  mitglieder  \n",
       "11                          https://www.doppstadt.de/          NaN  mitglieder  \n",
       "12                            https://ecologicon.com/          NaN  mitglieder  \n",
       "13            https://www.eew-energyfromwaste.com/de/          NaN  mitglieder  \n",
       "14                               https://www.ese.com/          NaN  mitglieder  \n",
       "15                            https://www.euwelle.de/          NaN  mitglieder  \n",
       "16    https://www.eggersmann-recyclingtechnology.com/          NaN  mitglieder  \n",
       "17                              https://www.faun.com/          NaN  mitglieder  \n",
       "18                     https://steinertglobal.com/de/          NaN  mitglieder  \n",
       "19                         https://www.ab-circular.de          NaN  mitglieder  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path('data')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "combined_path = out_dir / 'retech_scrape.csv'\n",
    "\n",
    "# Lade Mitglieder (falls nicht bereits im RAM)\n",
    "df_mem = None\n",
    "p = out_dir / 'retech_mitglieder.csv'\n",
    "if p.exists():\n",
    "    df_mem = pd.read_csv(p)\n",
    "else:\n",
    "    try:\n",
    "        df_mem = df.copy()\n",
    "    except NameError:\n",
    "        df_mem = pd.DataFrame(columns=['category','name','website_url','retech_profile_url'])\n",
    "\n",
    "# Normalisieren\n",
    "if df_mem is not None and not df_mem.empty:\n",
    "    df_mem = df_mem.rename(columns={\n",
    "        'category': 'section',\n",
    "        'website_url': 'url',\n",
    "        'retech_profile_url': 'profile_url',\n",
    "    })\n",
    "    if 'section' not in df_mem.columns:\n",
    "        df_mem['section'] = 'mitglieder'\n",
    "    df_mem['source_page'] = 'mitglieder'\n",
    "\n",
    "# Einheitliches Schema\n",
    "cols = ['section','name','url','profile_url','source_page']\n",
    "if df_mem is None or df_mem.empty:\n",
    "    df_all = pd.DataFrame(columns=cols)\n",
    "else:\n",
    "    df_all = df_mem.copy()\n",
    "    for c in cols:\n",
    "        if c not in df_all.columns:\n",
    "            df_all[c] = None\n",
    "\n",
    "# Deduplizieren und sortieren\n",
    "df_all = df_all.drop_duplicates(subset=['name','url']).sort_values(by=['source_page','section','name','url'], na_position='last').reset_index(drop=True)\n",
    "\n",
    "# Speichern\n",
    "df_all.to_csv(combined_path, index=False)\n",
    "print(f'Saved {len(df_all)} combined rows to {combined_path}')\n",
    "try:\n",
    "    print(df_all.groupby(['source_page','section']).size())\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "df_all.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zufallsstichprobe\n",
    "df_all.sample(10) if len(df_all) >= 10 else df_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Innoscence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
