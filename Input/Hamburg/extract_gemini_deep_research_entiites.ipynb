{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3e20c4",
   "metadata": {},
   "source": [
    "# Extract entities from Gemini DOCX tables\n",
    "This notebook parses the file `22-10-2025_Gemini_Hamburg Circular Economy Ecosystem Actors.docx` and extracts entities for later scraping:\n",
    "- section (from surrounding headings)\n",
    "- organization name\n",
    "- contact person (if present)\n",
    "- website URL\n",
    "It writes the results to `data/gemini_deep_research_entities.csv` and prints a quick preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8cb58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing python-docx…\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /home/thiesen/.local/lib/python3.11/site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /home/thiesen/.conda/envs/AI_Innoscence/lib/python3.11/site-packages (from python-docx) (4.15.0)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# Install/import dependencies\n",
    "import sys, subprocess, importlib, pathlib, re\n",
    "from typing import Optional, Tuple, Iterable, Dict, List\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def ensure_package(pkg: str, import_name: Optional[str] = None):\n",
    "    try:\n",
    "        return importlib.import_module(import_name or pkg)\n",
    "    except Exception:\n",
    "        print(f\"Installing {pkg}…\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "        return importlib.import_module(import_name or pkg)\n",
    "\n",
    "docx = ensure_package('python-docx', 'docx')\n",
    "Document = docx.Document\n",
    "try:\n",
    "    # optional fallback for merged cells parsing\n",
    "    docx2python = importlib.import_module('docx2python')\n",
    "except Exception:\n",
    "    docx2python = None\n",
    "    # Uncomment to install if needed\n",
    "    # docx2python = ensure_package('docx2python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3f3994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from 22-10-2025_Gemini_Hamburg Circular Economy Ecosystem Actors.docx\n"
     ]
    }
   ],
   "source": [
    "# Paths and setup\n",
    "ROOT = pathlib.Path('.')\n",
    "DOCX_PATH = ROOT / '22-10-2025_Gemini_Hamburg Circular Economy Ecosystem Actors.docx'\n",
    "OUT_DIR = ROOT / 'data'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_CSV = OUT_DIR / 'gemini_deep_research_entities.csv'\n",
    "\n",
    "assert DOCX_PATH.exists(), f\"DOCX file not found: {DOCX_PATH}\"\n",
    "print(f'Reading from {DOCX_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ddfdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "URL_RE = re.compile(r'(https?://[^\\s)]+)')\n",
    "DOMAIN_RE = re.compile(r'\\b(?:[a-z0-9][a-z0-9.-]*\\.[a-z]{2,})(?:/[^\\s]*)?', re.I)\n",
    "\n",
    "def clean(s: str | None) -> str:\n",
    "    if not s: return ''\n",
    "    return re.sub(r'\\s+', ' ', s).strip()\n",
    "\n",
    "def normalize_url(u: str | None) -> str:\n",
    "    if not u: return ''\n",
    "    u = u.strip().strip(').,;')\n",
    "    # remove trailing whitespace-number artifacts like \" 3  2  2\"\n",
    "    u = re.sub(r'\\s+\\d+(?:\\s+\\d+)*$', '', u)\n",
    "    if not re.match(r'^https?://', u):\n",
    "        u = 'https://' + u\n",
    "    # drop obvious trackers\n",
    "    u = re.sub(r'([?&](utm_[^=&]+|gclid|fbclid)=[^&]*)', '', u)\n",
    "    u = u.replace('?&', '?').rstrip('?&')\n",
    "    return u\n",
    "\n",
    "def extract_first_url(text: str | None) -> Optional[str]:\n",
    "    if not text:\n",
    "        return None\n",
    "    m = URL_RE.search(text)\n",
    "    if m:\n",
    "        return normalize_url(m.group(1))\n",
    "    m2 = DOMAIN_RE.search(text)\n",
    "    if m2:\n",
    "        return normalize_url(m2.group(0))\n",
    "    return None\n",
    "\n",
    "def is_person_like(name: str) -> bool:\n",
    "    if not name: return False\n",
    "    s = name.strip()\n",
    "    low = s.lower()\n",
    "    if any(t in low for t in ['prof', 'dr.', 'dr ', 'dipl.-', 'ing.', 'jr.', 'sr.','prof.']):\n",
    "        return True\n",
    "    toks = [t for t in re.split(r'[^A-Za-zÄÖÜäöüß-]+', s) if t]\n",
    "    caps = sum(1 for t in toks if t and t[0].isupper())\n",
    "    return caps >= 2 and len(toks) <= 5\n",
    "\n",
    "def guess_org_from_url(url: str) -> str:\n",
    "    host = urlparse(url).netloc.lower().replace('www.','')\n",
    "    if not host:\n",
    "        return ''\n",
    "    parts = host.split('.')\n",
    "    if len(parts) >= 2:\n",
    "        sld = parts[-2]\n",
    "        return sld.capitalize()\n",
    "    return host.capitalize()\n",
    "\n",
    "HEADER_SYNONYMS: Dict[str,str] = {\n",
    "    'organization':'organization','organisation':'organization','name':'organization','entity':'organization','actor':'organization','company':'organization','institution':'organization',\n",
    "    'contact':'contact_person','contact person':'contact_person','contact name':'contact_person','person':'contact_person','ansprechpartner':'contact_person','ansprechpartnerin':'contact_person',\n",
    "    'website':'website_url','webseite':'website_url','url':'website_url','link':'website_url','homepage':'website_url','web':'website_url','www':'website_url'\n",
    "}\n",
    "\n",
    "def norm_header(h: str) -> str:\n",
    "    h = clean(h).lower()\n",
    "    h = re.sub(r'[^a-z0-9\\s]', ' ', h)\n",
    "    h = re.sub(r'\\s+', ' ', h).strip()\n",
    "    return HEADER_SYNONYMS.get(h, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b753c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate DOCX in document order to capture sections and tables\n",
    "from docx.document import Document as _Document\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from docx.table import _Cell, Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "\n",
    "def iter_block_items(parent):\n",
    "    if isinstance(parent, _Document):\n",
    "        parent_elm = parent.element.body\n",
    "    elif isinstance(parent, _Cell):\n",
    "        parent_elm = parent._tc\n",
    "    else:\n",
    "        raise ValueError(\"Unknown parent type\")\n",
    "    for child in parent_elm.iterchildren():\n",
    "        if isinstance(child, CT_P):\n",
    "            yield Paragraph(child, parent)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            yield Table(child, parent)\n",
    "\n",
    "def heading_level(p: Paragraph) -> int | None:\n",
    "    try:\n",
    "        name = p.style.name or ''\n",
    "    except Exception:\n",
    "        name = ''\n",
    "    m = re.match(r'Heading\\s*(\\d+)', name)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    # also accept German 'Überschrift'\n",
    "    m2 = re.match(r'Überschrift\\s*(\\d+)', name)\n",
    "    if m2:\n",
    "        return int(m2.group(1))\n",
    "    return None\n",
    "\n",
    "def cell_text(cell) -> str:\n",
    "    # python-docx cell.text already joins runs with newlines; we normalize whitespace\n",
    "    return clean(cell.text)\n",
    "\n",
    "def table_to_matrix(tbl: Table) -> list[list[str]]:\n",
    "    rows = []\n",
    "    for r in tbl.rows:\n",
    "        rows.append([cell_text(c) for c in r.cells])\n",
    "    return rows\n",
    "\n",
    "def find_header_row(mat: List[List[str]]) -> Tuple[int, List[str]]:\n",
    "    # default to first non-empty row\n",
    "    for idx, row in enumerate(mat):\n",
    "        non_empty = sum(1 for x in row if clean(x))\n",
    "        if non_empty >= max(1, len(row)//2):\n",
    "            headers = [norm_header(h) for h in row]\n",
    "            return idx, headers\n",
    "    return 0, [norm_header(h) for h in (mat[0] if mat else [])]\n",
    "\n",
    "def extract_url_from_row(row: List[str]) -> Optional[str]:\n",
    "    for cell in row:\n",
    "        u = extract_first_url(cell)\n",
    "        if u:\n",
    "            return u\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80f1435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docx_entities(path: pathlib.Path) -> pd.DataFrame:\n",
    "    doc = Document(str(path))\n",
    "    current_section = ''\n",
    "    all_rows = []\n",
    "    tbl_idx = -1\n",
    "    for block in iter_block_items(doc):\n",
    "        if isinstance(block, Paragraph):\n",
    "            lvl = heading_level(block)\n",
    "            if lvl is not None and lvl <= 3:\n",
    "                txt = clean(block.text)\n",
    "                if txt:\n",
    "                    current_section = txt\n",
    "        else:  # Table\n",
    "            tbl_idx += 1\n",
    "            mat = table_to_matrix(block)\n",
    "            if not mat:\n",
    "                continue\n",
    "            hdr_idx, headers = find_header_row(mat)\n",
    "            # map columns\n",
    "            col_map: Dict[str,int] = {}\n",
    "            for j, h in enumerate(headers):\n",
    "                if h in ('organization','contact_person','website_url'):\n",
    "                    col_map[h] = j\n",
    "            data_start = hdr_idx + 1\n",
    "            for i in range(data_start, len(mat)):\n",
    "                row = mat[i]\n",
    "                org = ''\n",
    "                contact = ''\n",
    "                url = ''\n",
    "                if 'organization' in col_map and col_map['organization'] < len(row):\n",
    "                    org = clean(row[col_map['organization']])\n",
    "                if 'contact_person' in col_map and col_map['contact_person'] < len(row):\n",
    "                    contact = clean(row[col_map['contact_person']])\n",
    "                if 'website_url' in col_map and col_map['website_url'] < len(row):\n",
    "                    url = extract_first_url(row[col_map['website_url']]) or ''\n",
    "                if not url:\n",
    "                    url = extract_url_from_row(row) or ''\n",
    "                # if no explicit org, try to infer from other cells or url\n",
    "                if not org:\n",
    "                    # pick the longest non-url cell\n",
    "                    cand_cells = [c for c in row if c and not URL_RE.search(c)]\n",
    "                    cand_cells.sort(key=lambda x: len(x), reverse=True)\n",
    "                    org = clean(cand_cells[0]) if cand_cells else ''\n",
    "                # contact heuristic\n",
    "                if not contact:\n",
    "                    for c in row:\n",
    "                        if is_person_like(c):\n",
    "                            contact = clean(c)\n",
    "                            break\n",
    "                # if still no org, use host from url\n",
    "                if not org and url:\n",
    "                    org = guess_org_from_url(url)\n",
    "                if url:\n",
    "                    url = normalize_url(url)\n",
    "                if not any([org, contact, url]):\n",
    "                    continue\n",
    "                all_rows.append({\n",
    "                    'section': current_section,\n",
    "                    'organization': org,\n",
    "                    'contact_person': contact,\n",
    "                    'website_url': url,\n",
    "                    'source_table_index': tbl_idx,\n",
    "                    'source_row_index': i,\n",
    "                })\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "    # cleanup and dedupe\n",
    "    for col in ['section','organization','contact_person','website_url']:\n",
    "        df[col] = df[col].astype(str).map(clean)\n",
    "    df['website_url'] = df['website_url'].map(normalize_url)\n",
    "    # Drop rows with clearly invalid URLs (just numbers etc.)\n",
    "    df = df[~df['website_url'].str.match(r'^https?://\\s*$')]\n",
    "    df = df.drop_duplicates(subset=['organization','website_url']).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82580058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: 14\n",
      "index  rows  cols\n",
      "    0     9     2\n",
      "    1     7     2\n",
      "    2     6     2\n",
      "    3    10     2\n",
      "    4    11     2\n",
      "    5    11     2\n",
      "    6     8     2\n",
      "    7     5     2\n",
      "    8     4     2\n",
      "    9     2     2\n",
      "   10     5     2\n",
      "   11     7     2\n",
      "   12     6     2\n",
      "   13     7     2\n"
     ]
    }
   ],
   "source": [
    "# Load and inventory tables\n",
    "doc = Document(str(DOCX_PATH))\n",
    "num_tables = len(doc.tables)\n",
    "summary = [(i, len(t.rows), len(t.columns)) for i, t in enumerate(doc.tables)]\n",
    "print(f\"Tables: {num_tables}\")\n",
    "print(\"index  rows  cols\")\n",
    "for i, r, c in summary[:20]:\n",
    "    print(f\"{i:>5}  {r:>4}  {c:>4}\")\n",
    "if num_tables > 20:\n",
    "    print(\"… (truncated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e327e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 84 entities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>organization</th>\n",
       "      <th>contact_person</th>\n",
       "      <th>website_url</th>\n",
       "      <th>source_table_index</th>\n",
       "      <th>source_row_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Students</td>\n",
       "      <td>AStA TUHH (Department for Sustainability)</td>\n",
       "      <td>AStA TUHH (Department for Sustainability)</td>\n",
       "      <td>https://www.asta.tuhh.de/mitglieder/nachhaltig...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Students</td>\n",
       "      <td>AStA University of Hamburg (Department for Sus...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.bwl.uni-hamburg.de/en/transfer/kar...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Students</td>\n",
       "      <td>AStA HAW Hamburg</td>\n",
       "      <td>AStA HAW Hamburg</td>\n",
       "      <td>https://www.haw-hamburg.de/studium/campusleben...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Students</td>\n",
       "      <td>AStA HCU Hamburg</td>\n",
       "      <td>AStA HCU Hamburg</td>\n",
       "      <td>https://asta-hcu.de/projekte-und-initiativen/</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Students</td>\n",
       "      <td>Green Office University of Hamburg</td>\n",
       "      <td>Green Office University of Hamburg</td>\n",
       "      <td>https://www.bwl.uni-hamburg.de/en/transfer/kar...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Students</td>\n",
       "      <td>Green Office HAW Hamburg</td>\n",
       "      <td>Green Office HAW Hamburg</td>\n",
       "      <td>https://www.haw-hamburg.de/ftz-nk/green-office/</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Students</td>\n",
       "      <td>Impact Week: Sustainability (TUHH)</td>\n",
       "      <td>Impact Week: Sustainability (TUHH)</td>\n",
       "      <td>https://www.tuhh.de/uif/en/projects</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Students</td>\n",
       "      <td>AI for Sustainable Development Competition (HA...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.haw-hamburg.de/detail/news/news/sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Researchers</td>\n",
       "      <td>Prof. Dr. Fenna Blomsma (University of Hamburg)</td>\n",
       "      <td>Prof. Dr. Fenna Blomsma (University of Hamburg)</td>\n",
       "      <td>https://www.climate-kic.org/spotlight-initiati...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Researchers</td>\n",
       "      <td>Longwitz Research Group (RG Longwitz) (Univers...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.chemie.uni-hamburg.de/en/institute...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Researchers</td>\n",
       "      <td>Sustainable Innovation Research Group (TUHH)</td>\n",
       "      <td>Sustainable Innovation Research Group (TUHH)</td>\n",
       "      <td>https://www.tuhh.de/tim/en/translate-to-englis...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Researchers</td>\n",
       "      <td>Prof. Kerstin Kuchta (TUHH)</td>\n",
       "      <td>Prof. Kerstin Kuchta (TUHH)</td>\n",
       "      <td>https://hamburg-business.com/en/news/circular-...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Researchers</td>\n",
       "      <td>Dr. Henning Wilts (HCU Hamburg &amp; Wuppertal Ins...</td>\n",
       "      <td>Dr. Henning Wilts (HCU Hamburg &amp; Wuppertal Ins...</td>\n",
       "      <td>https://forschungsportal.hcu-hamburg.de/en/org...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Researchers</td>\n",
       "      <td>Dr. Joao Eustachio (HAW Hamburg)</td>\n",
       "      <td>Dr. Joao Eustachio (HAW Hamburg)</td>\n",
       "      <td>https://www.haw-hamburg.de/hochschule/beschaef...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Higher Education Institutions</td>\n",
       "      <td>Hamburg University of Technology (TUHH)</td>\n",
       "      <td>Hamburg University of Technology (TUHH)</td>\n",
       "      <td>https://www.tuhh.de/</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Higher Education Institutions</td>\n",
       "      <td>Hamburg University of Applied Sciences (HAW Ha...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.haw-hamburg.de/</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Higher Education Institutions</td>\n",
       "      <td>HafenCity University (HCU) Hamburg</td>\n",
       "      <td>HafenCity University (HCU) Hamburg</td>\n",
       "      <td>https://www.hcu-hamburg.de/</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Higher Education Institutions</td>\n",
       "      <td>Helmut Schmidt University (HSU)</td>\n",
       "      <td>Helmut Schmidt University (HSU)</td>\n",
       "      <td>https://www.hsu-hh.de/</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Higher Education Institutions</td>\n",
       "      <td>University of Hamburg (UHH)</td>\n",
       "      <td>University of Hamburg (UHH)</td>\n",
       "      <td>https://www.uni-hamburg.de/</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Research Institutes</td>\n",
       "      <td>Hamburg Institute for Innovation, Climate Prot...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.hiicce.de/en/</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          section  \\\n",
       "0                        Students   \n",
       "1                        Students   \n",
       "2                        Students   \n",
       "3                        Students   \n",
       "4                        Students   \n",
       "5                        Students   \n",
       "6                        Students   \n",
       "7                        Students   \n",
       "8                     Researchers   \n",
       "9                     Researchers   \n",
       "10                    Researchers   \n",
       "11                    Researchers   \n",
       "12                    Researchers   \n",
       "13                    Researchers   \n",
       "14  Higher Education Institutions   \n",
       "15  Higher Education Institutions   \n",
       "16  Higher Education Institutions   \n",
       "17  Higher Education Institutions   \n",
       "18  Higher Education Institutions   \n",
       "19            Research Institutes   \n",
       "\n",
       "                                         organization  \\\n",
       "0           AStA TUHH (Department for Sustainability)   \n",
       "1   AStA University of Hamburg (Department for Sus...   \n",
       "2                                    AStA HAW Hamburg   \n",
       "3                                    AStA HCU Hamburg   \n",
       "4                  Green Office University of Hamburg   \n",
       "5                            Green Office HAW Hamburg   \n",
       "6                  Impact Week: Sustainability (TUHH)   \n",
       "7   AI for Sustainable Development Competition (HA...   \n",
       "8     Prof. Dr. Fenna Blomsma (University of Hamburg)   \n",
       "9   Longwitz Research Group (RG Longwitz) (Univers...   \n",
       "10       Sustainable Innovation Research Group (TUHH)   \n",
       "11                        Prof. Kerstin Kuchta (TUHH)   \n",
       "12  Dr. Henning Wilts (HCU Hamburg & Wuppertal Ins...   \n",
       "13                   Dr. Joao Eustachio (HAW Hamburg)   \n",
       "14            Hamburg University of Technology (TUHH)   \n",
       "15  Hamburg University of Applied Sciences (HAW Ha...   \n",
       "16                 HafenCity University (HCU) Hamburg   \n",
       "17                    Helmut Schmidt University (HSU)   \n",
       "18                        University of Hamburg (UHH)   \n",
       "19  Hamburg Institute for Innovation, Climate Prot...   \n",
       "\n",
       "                                       contact_person  \\\n",
       "0           AStA TUHH (Department for Sustainability)   \n",
       "1                                                       \n",
       "2                                    AStA HAW Hamburg   \n",
       "3                                    AStA HCU Hamburg   \n",
       "4                  Green Office University of Hamburg   \n",
       "5                            Green Office HAW Hamburg   \n",
       "6                  Impact Week: Sustainability (TUHH)   \n",
       "7                                                       \n",
       "8     Prof. Dr. Fenna Blomsma (University of Hamburg)   \n",
       "9                                                       \n",
       "10       Sustainable Innovation Research Group (TUHH)   \n",
       "11                        Prof. Kerstin Kuchta (TUHH)   \n",
       "12  Dr. Henning Wilts (HCU Hamburg & Wuppertal Ins...   \n",
       "13                   Dr. Joao Eustachio (HAW Hamburg)   \n",
       "14            Hamburg University of Technology (TUHH)   \n",
       "15                                                      \n",
       "16                 HafenCity University (HCU) Hamburg   \n",
       "17                    Helmut Schmidt University (HSU)   \n",
       "18                        University of Hamburg (UHH)   \n",
       "19                                                      \n",
       "\n",
       "                                          website_url  source_table_index  \\\n",
       "0   https://www.asta.tuhh.de/mitglieder/nachhaltig...                   0   \n",
       "1   https://www.bwl.uni-hamburg.de/en/transfer/kar...                   0   \n",
       "2   https://www.haw-hamburg.de/studium/campusleben...                   0   \n",
       "3       https://asta-hcu.de/projekte-und-initiativen/                   0   \n",
       "4   https://www.bwl.uni-hamburg.de/en/transfer/kar...                   0   \n",
       "5     https://www.haw-hamburg.de/ftz-nk/green-office/                   0   \n",
       "6                 https://www.tuhh.de/uif/en/projects                   0   \n",
       "7   https://www.haw-hamburg.de/detail/news/news/sh...                   0   \n",
       "8   https://www.climate-kic.org/spotlight-initiati...                   1   \n",
       "9   https://www.chemie.uni-hamburg.de/en/institute...                   1   \n",
       "10  https://www.tuhh.de/tim/en/translate-to-englis...                   1   \n",
       "11  https://hamburg-business.com/en/news/circular-...                   1   \n",
       "12  https://forschungsportal.hcu-hamburg.de/en/org...                   1   \n",
       "13  https://www.haw-hamburg.de/hochschule/beschaef...                   1   \n",
       "14                               https://www.tuhh.de/                   2   \n",
       "15                        https://www.haw-hamburg.de/                   2   \n",
       "16                        https://www.hcu-hamburg.de/                   2   \n",
       "17                             https://www.hsu-hh.de/                   2   \n",
       "18                        https://www.uni-hamburg.de/                   2   \n",
       "19                          https://www.hiicce.de/en/                   3   \n",
       "\n",
       "    source_row_index  \n",
       "0                  1  \n",
       "1                  2  \n",
       "2                  3  \n",
       "3                  4  \n",
       "4                  5  \n",
       "5                  6  \n",
       "6                  7  \n",
       "7                  8  \n",
       "8                  1  \n",
       "9                  2  \n",
       "10                 3  \n",
       "11                 4  \n",
       "12                 5  \n",
       "13                 6  \n",
       "14                 1  \n",
       "15                 2  \n",
       "16                 3  \n",
       "17                 4  \n",
       "18                 5  \n",
       "19                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/gemini_deep_research_entities.csv\n",
      "section\n",
      "Non-Governmental Organizations          10\n",
      "Industry Partners                       10\n",
      "Research Institutes                      9\n",
      "Students                                 8\n",
      "Startups and Entrepreneurs               7\n",
      "Researchers                              6\n",
      "Media and Communication Partners         6\n",
      "Knowledge and Innovation Communities     6\n",
      "Higher Education Institutions            5\n",
      "Funding Bodies                           5\n",
      "Public Authorities                       4\n",
      "Citizen Associations                     4\n",
      "Policy Makers                            3\n",
      "End-Users                                1\n"
     ]
    }
   ],
   "source": [
    "# Run extraction and save\n",
    "entities = parse_docx_entities(DOCX_PATH)\n",
    "print(f\"Extracted {len(entities)} entities\")\n",
    "if not entities.empty:\n",
    "    display(entities.head(20))\n",
    "    entities.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Saved to {OUT_CSV}\")\n",
    "    print(entities['section'].value_counts().to_string())\n",
    "else:\n",
    "    print('No entities found. Please review table structure or adjust header mapping.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Innoscence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
