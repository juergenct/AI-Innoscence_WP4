{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bea3a06",
   "metadata": {},
   "source": [
    "# Green NGOs of Moldova — site-wide NGO list extraction\n",
    "\n",
    "We scrape the NGO directory at https://www.greenngosofmoldova.org/ngos/.\n",
    "For each NGO tile, we follow its subpage (e.g., https://www.greenngosofmoldova.org/ngo/eteco/) and extract:\n",
    "- name\n",
    "- website (external link shown under “Web” on the NGO page)\n",
    "- domain (normalized)\n",
    "- source (subpage URL)\n",
    "\n",
    "Output: `Input/Cahul/green_ngos_of_moldova.csv`.\n",
    "\n",
    "We first use a static approach (requests + BeautifulSoup). If the index is paginated or tiles are lazy-loaded, we can extend this with pagination or a browser fallback later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db04165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiesen/.conda/envs/AI_Innoscence/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports & helpers\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import time\n",
    "from typing import List, Dict, Optional\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "INDEX_URL = \"https://www.greenngosofmoldova.org/ngos/\"\n",
    "BASE = \"https://www.greenngosofmoldova.org/\"\n",
    "notebook_dir = os.path.abspath(\".\")\n",
    "output_path = os.path.join(notebook_dir, \"green_ngos_of_moldova.csv\")\n",
    "\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121 Safari/537.36\",\n",
    "})\n",
    "\n",
    "SOCIAL = (\n",
    "    \"facebook.com\", \"twitter.com\", \"x.com\", \"instagram.com\", \"linkedin.com\",\n",
    "    \"youtube.com\", \"youtu.be\", \"t.me\", \"tiktok.com\", \"vk.com\"\n",
    ")\n",
    "\n",
    "\n",
    "def fetch_html(url: str, retries: int = 2, timeout: int = 30) -> Optional[str]:\n",
    "    for i in range(retries + 1):\n",
    "        try:\n",
    "            r = SESSION.get(url, timeout=timeout)\n",
    "            if r.status_code == 200:\n",
    "                return r.text\n",
    "        except Exception:\n",
    "            time.sleep(1 + i)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_soup(url: str) -> Optional[BeautifulSoup]:\n",
    "    html = fetch_html(url)\n",
    "    if not html:\n",
    "        return None\n",
    "    return BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "\n",
    "def extract_domain(u: str) -> str:\n",
    "    try:\n",
    "        host = urlparse(u).netloc.lower()\n",
    "        return host[4:] if host.startswith(\"www.\") else host\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def is_external(u: str) -> bool:\n",
    "    try:\n",
    "        net = urlparse(u).netloc.lower()\n",
    "        return net and \"greenngosofmoldova.org\" not in net\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_social(u: str) -> bool:\n",
    "    u = (u or '').lower()\n",
    "    return any(s in u for s in SOCIAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2ab5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index parser — find NGO tiles and subpage URLs\n",
    "\n",
    "def get_index_entries(url: str = INDEX_URL) -> List[Dict]:\n",
    "    soup = get_soup(url)\n",
    "    if not soup:\n",
    "        print(\"Failed to load index page\")\n",
    "        return []\n",
    "\n",
    "    rows: List[Dict] = []\n",
    "    # Heuristic: tiles likely link to /ngo/<slug>/ via anchors\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        href = a['href']\n",
    "        if not href:\n",
    "            continue\n",
    "        full = urljoin(BASE, href)\n",
    "        if '/ngo/' in full and full.startswith('https://www.greenngosofmoldova.org/ngo/'):\n",
    "            # Infer a name: either anchor text, alt on image, or surrounding heading\n",
    "            name = (a.get_text(\" \") or \"\").strip()\n",
    "            if not name:\n",
    "                img = a.find('img', alt=True)\n",
    "                if img and img.get('alt'):\n",
    "                    name = img['alt'].strip()\n",
    "            if not name:\n",
    "                # try heading near the link\n",
    "                h = a.find_next(['h2','h3']) or a.find_previous(['h2','h3'])\n",
    "                if h:\n",
    "                    name = (h.get_text(\" \") or \"\").strip()\n",
    "            rows.append({ 'name': name, 'subpage': full })\n",
    "\n",
    "    # Dedupe by subpage\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        if r['subpage'] in seen:\n",
    "            continue\n",
    "        seen.add(r['subpage'])\n",
    "        out.append(r)\n",
    "\n",
    "    print(f\"Index entries discovered: {len(out)}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcdcde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index entries discovered: 19\n",
      "Total NGOs scraped: 19\n",
      "Wrote /home/thiesen/Documents/AI-Innoscence_Ecosystem/Input/Cahul/green_ngos_of_moldova.csv\n"
     ]
    }
   ],
   "source": [
    "# Subpage parser — extract website from NGO page\n",
    "\n",
    "def get_website_from_subpage(url: str) -> str:\n",
    "    soup = get_soup(url)\n",
    "    if not soup:\n",
    "        return \"\"\n",
    "\n",
    "    # 1) Prefer anchors that are external and not social\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        href = a['href']\n",
    "        if href.startswith('mailto:') or href.startswith('tel:'):\n",
    "            continue\n",
    "        full = urljoin(url, href)\n",
    "        if is_external(full) and not is_social(full):\n",
    "            return full\n",
    "\n",
    "    # 2) Fallback: look for text blocks containing 'Web' and an URL-like token\n",
    "    text = soup.get_text(\" \", strip=True)\n",
    "    import re\n",
    "    m = re.search(r\"\\bWeb\\b\\s+((?:https?://)?(?:www\\.)?[A-Za-z0-9.-]+\\.[A-Za-z]{2,}(?:/\\S*)?)\", text, re.IGNORECASE)\n",
    "    if m:\n",
    "        val = m.group(1)\n",
    "        if not val.lower().startswith(('http://', 'https://')):\n",
    "            val = 'https://' + val if val.lower().startswith('www.') else 'http://' + val\n",
    "        if is_external(val) and not is_social(val):\n",
    "            return val\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def scrape_all() -> List[Dict]:\n",
    "    entries = get_index_entries(INDEX_URL)\n",
    "    rows: List[Dict] = []\n",
    "    for e in entries:\n",
    "        name = (e.get('name') or '').strip()\n",
    "        sub = e['subpage']\n",
    "        site = get_website_from_subpage(sub)\n",
    "        rows.append({\n",
    "            'name': name,\n",
    "            'website': site,\n",
    "            'domain': extract_domain(site) if site else '',\n",
    "            'source': sub,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "rows = scrape_all()\n",
    "print(f\"Total NGOs scraped: {len(rows)}\")\n",
    "\n",
    "# Write CSV\n",
    "pd.DataFrame(rows).to_csv(output_path, index=False)\n",
    "print(f\"Wrote {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0fe4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>website</th>\n",
       "      <th>domain</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EtEcO</td>\n",
       "      <td>http://etecotiras.ru/</td>\n",
       "      <td>etecotiras.ru</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/eteco/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EcoPMR</td>\n",
       "      <td>https://ekopmr.ru/</td>\n",
       "      <td>ekopmr.ru</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/ecovisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVD</td>\n",
       "      <td>http://www.e-circular.org</td>\n",
       "      <td>e-circular.org</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/avd/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFPMDD</td>\n",
       "      <td>http://www.mediu.md</td>\n",
       "      <td>mediu.md</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/afpmdd/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gutta-Club</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/gutta-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Media-Grup MERIDIAN</td>\n",
       "      <td>http://www.ecofm.md</td>\n",
       "      <td>ecofm.md</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/meridian/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AJMTEM</td>\n",
       "      <td>https://ecopresa.md/</td>\n",
       "      <td>ecopresa.md</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/ajmtem/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Medics for Ecology</td>\n",
       "      <td>http://dr-ecology.blogspot.com/</td>\n",
       "      <td>dr-ecology.blogspot.com</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/medics-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MEM</td>\n",
       "      <td>http://www.mem.md</td>\n",
       "      <td>mem.md</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/mem/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MEGA</td>\n",
       "      <td>http://megageneration.com</td>\n",
       "      <td>megageneration.com</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/mega/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NEC – National Environmental Center</td>\n",
       "      <td>https://policies.google.com/privacy?hl=en&amp;gl=en</td>\n",
       "      <td>policies.google.com</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/nationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BIOTICA</td>\n",
       "      <td>http://www.bioticamoldova.org/</td>\n",
       "      <td>bioticamoldova.org</td>\n",
       "      <td>https://www.greenngosofmoldova.org/ngo/biotica/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  \\\n",
       "0                                 EtEcO   \n",
       "1                                EcoPMR   \n",
       "2                                   AVD   \n",
       "3                                AFPMDD   \n",
       "4                            Gutta-Club   \n",
       "5                   Media-Grup MERIDIAN   \n",
       "6                                AJMTEM   \n",
       "7                    Medics for Ecology   \n",
       "8                                   MEM   \n",
       "9                                  MEGA   \n",
       "10  NEC – National Environmental Center   \n",
       "11                              BIOTICA   \n",
       "\n",
       "                                            website                   domain  \\\n",
       "0                             http://etecotiras.ru/            etecotiras.ru   \n",
       "1                                https://ekopmr.ru/                ekopmr.ru   \n",
       "2                         http://www.e-circular.org           e-circular.org   \n",
       "3                               http://www.mediu.md                 mediu.md   \n",
       "4                                               NaN                      NaN   \n",
       "5                               http://www.ecofm.md                 ecofm.md   \n",
       "6                              https://ecopresa.md/              ecopresa.md   \n",
       "7                   http://dr-ecology.blogspot.com/  dr-ecology.blogspot.com   \n",
       "8                                 http://www.mem.md                   mem.md   \n",
       "9                         http://megageneration.com       megageneration.com   \n",
       "10  https://policies.google.com/privacy?hl=en&gl=en      policies.google.com   \n",
       "11                   http://www.bioticamoldova.org/       bioticamoldova.org   \n",
       "\n",
       "                                               source  \n",
       "0       https://www.greenngosofmoldova.org/ngo/eteco/  \n",
       "1   https://www.greenngosofmoldova.org/ngo/ecovisi...  \n",
       "2         https://www.greenngosofmoldova.org/ngo/avd/  \n",
       "3      https://www.greenngosofmoldova.org/ngo/afpmdd/  \n",
       "4   https://www.greenngosofmoldova.org/ngo/gutta-c...  \n",
       "5    https://www.greenngosofmoldova.org/ngo/meridian/  \n",
       "6      https://www.greenngosofmoldova.org/ngo/ajmtem/  \n",
       "7   https://www.greenngosofmoldova.org/ngo/medics-...  \n",
       "8         https://www.greenngosofmoldova.org/ngo/mem/  \n",
       "9        https://www.greenngosofmoldova.org/ngo/mega/  \n",
       "10  https://www.greenngosofmoldova.org/ngo/nationa...  \n",
       "11    https://www.greenngosofmoldova.org/ngo/biotica/  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites present: 19\n"
     ]
    }
   ],
   "source": [
    "# Preview a sample\n",
    "import os\n",
    "if os.path.exists(output_path):\n",
    "    df = pd.read_csv(output_path)\n",
    "    print(df.shape)\n",
    "    display(df.head(12))\n",
    "    print(\"Websites present:\", (df['website'].astype(str)!='').sum())\n",
    "else:\n",
    "    print(\"CSV not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Innoscence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
