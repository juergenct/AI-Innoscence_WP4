{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c7d047",
   "metadata": {},
   "source": [
    "# Extract NTPNS Members (name + website) across all categories\n",
    "\n",
    "Scrape https://www.ntpns.rs/members?lang=en for all categories (Startups, R&D Companies, Research Institutes, Virtual Members, Innovation Partners).\n",
    "For each entity, capture:\n",
    "\n",
    "- name\n",
    "- website (from the \"Visit Website\" button in the modal, when available)\n",
    "- category\n",
    "\n",
    "Saves to `ntpns_members.csv` in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93759a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import time, re, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from playwright.sync_api import TimeoutError as PlaywrightTimeout\n",
    "import asyncio, nest_asyncio\n",
    "from playwright.async_api import async_playwright, TimeoutError as AsyncPlaywrightTimeout\n",
    "\n",
    "BASE_URL = \"https://www.ntpns.rs/members?lang=en\"\n",
    "\n",
    "CATEGORIES = [\n",
    "    \"Startups\",\n",
    "    \"R&D Companies\",\n",
    "    \"Research Institutes\",\n",
    "    \"Virtual Members\",\n",
    "    \"Innovation Partners\",\n",
    "]\n",
    "\n",
    "# Tunable timeouts (ms) to keep runs snappy in notebooks\n",
    "PAGE_TIMEOUT = 6000\n",
    "TAB_CLICK_TIMEOUT = 800\n",
    "MODAL_TIMEOUT = 2000\n",
    "CARD_HEADING_TIMEOUT = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c7dc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEWARE: your OS is not officially supported by Playwright; downloading fallback build for ubuntu20.04-x64.\n",
      "BEWARE: your OS is not officially supported by Playwright; downloading fallback build for ubuntu20.04-x64.\n",
      "BEWARE: your OS is not officially supported by Playwright; downloading fallback build for ubuntu20.04-x64.\n"
     ]
    }
   ],
   "source": [
    "# Ensure Chromium is available for Playwright (safe no-op if already installed)\n",
    "import sys, subprocess\n",
    "try:\n",
    "    subprocess.run([sys.executable, '-m', 'playwright', 'install', 'chromium'], check=False, stdout=None, stderr=None)\n",
    "except Exception as e:\n",
    "    print('Playwright install hint:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd23d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening page…\n",
      "Category: Startups … Category: Startups … 33 cards\n",
      "33 cards\n",
      "Category: R&D Companies … Category: R&D Companies … 25 cards\n",
      "25 cards\n",
      "Category: Research Institutes … Category: Research Institutes … 1 cards\n",
      "1 cards\n",
      "Category: Virtual Members … Category: Virtual Members … 0 cards\n",
      "Category: Innovation Partners … 0 cards\n",
      "Category: Innovation Partners … 0 cards\n",
      "0 cards\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape function using Playwright (async, with robust website capture + card-level fallbacks)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def _norm_text(t: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (t or \"\").strip())\n",
    "\n",
    "def _unique_preserve(seq):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for s in seq:\n",
    "        if s in seen:\n",
    "            continue\n",
    "        seen.add(s)\n",
    "        out.append(s)\n",
    "    return out\n",
    "\n",
    "async def scrape_ntpns_async():\n",
    "    rows = []\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "        page.set_default_timeout(PAGE_TIMEOUT)\n",
    "        print('Opening page…')\n",
    "        await page.goto(BASE_URL, wait_until='load')\n",
    "        try:\n",
    "            await page.wait_for_load_state('networkidle', timeout=3000)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Accept cookies if present\n",
    "        try:\n",
    "            await page.get_by_role('button', name=re.compile('accept|agree', re.I)).click(timeout=2000)\n",
    "        except Exception:\n",
    "            pass\n",
    "        for cat in CATEGORIES:\n",
    "            print(f'Category: {cat} …', end=' ')\n",
    "            # Click category tab using multiple strategies\n",
    "            clicked = False\n",
    "            for locator in [\n",
    "                page.get_by_role('tab', name=cat),\n",
    "                page.get_by_role('button', name=cat),\n",
    "                page.get_by_role('link', name=cat),\n",
    "                page.get_by_text(cat, exact=False),\n",
    "            ]:\n",
    "                try:\n",
    "                    await locator.first.click(timeout=TAB_CLICK_TIMEOUT)\n",
    "                    clicked = True\n",
    "                    break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if not clicked:\n",
    "                print('[tab not found]')\n",
    "                continue\n",
    "            # Collect visible unique card names from H3 headings only\n",
    "            await page.wait_for_timeout(500)\n",
    "            raw_names = await page.locator('h3:visible').all_text_contents()\n",
    "            names = _unique_preserve([_norm_text(n) for n in raw_names if _norm_text(n)])\n",
    "            print(f'{len(names)} cards')\n",
    "            for name in names:\n",
    "                website = None\n",
    "                # Try multiple robust ways to open the card modal by its heading\n",
    "                opened = False\n",
    "                heading = page.locator('h3').filter(has_text=name).first\n",
    "                try:\n",
    "                    await heading.scroll_into_view_if_needed(timeout=800)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                # Strategy 1: direct click\n",
    "                try:\n",
    "                    await heading.click(timeout=TAB_CLICK_TIMEOUT)\n",
    "                    opened = True\n",
    "                except Exception:\n",
    "                    pass\n",
    "                # Strategy 2: click closest clickable ancestor via JS (broadened)\n",
    "                if not opened:\n",
    "                    try:\n",
    "                        el = await heading.element_handle()\n",
    "                        if el:\n",
    "                            await page.evaluate('(el) => { const sel = \"a,button,[role=button],[onclick], .card, .member, .company, .item, .startup\"; const c = el.closest(sel); if (c) c.click(); }', el)\n",
    "                            opened = True\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                # Strategy 3: force click on heading\n",
    "                if not opened:\n",
    "                    try:\n",
    "                        await heading.click(timeout=TAB_CLICK_TIMEOUT, force=True)\n",
    "                        opened = True\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                # Strategy 4: click by bounding box center\n",
    "                if not opened:\n",
    "                    try:\n",
    "                        box = await heading.bounding_box()\n",
    "                        if box:\n",
    "                            await page.mouse.click(box['x'] + box['width']/2, box['y'] + box['height']/2)\n",
    "                            opened = True\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                # Attempt to extract website directly from the card tile if modal didn't open\n",
    "                if not opened and website is None:\n",
    "                    try:\n",
    "                        el = await heading.element_handle()\n",
    "                        if el:\n",
    "                            urls = await page.evaluate(\"\"\"(h)=>{\n",
    "                                function collectFrom(node){\n",
    "                                  const urls = new Set();\n",
    "                                  const add=u=>{ if(u && /^https?:\\/\\//i.test(u)) urls.add(u); };\n",
    "                                  let cur=node;\n",
    "                                  for(let i=0;i<5 && cur;i++, cur=cur.parentElement){\n",
    "                                    cur.querySelectorAll('a[href]').forEach(a=>add(a.getAttribute('href')));\n",
    "                                    cur.querySelectorAll('[data-href]').forEach(a=>add(a.getAttribute('data-href')));\n",
    "                                    const oc = cur.getAttribute('onclick') || '';\n",
    "                                    const m = oc.match(/https?:\\/\\/[^'\\\"\\s)]+/i);\n",
    "                                    if(m) add(m[0]);\n",
    "                                  }\n",
    "                                  return Array.from(urls);\n",
    "                                }\n",
    "                                return collectFrom(h);\n",
    "                            \"\"\" , el)\n",
    "                            # Prefer external (non-ntpns) links first\n",
    "                            ext = [u for u in urls if 'ntpns.rs' not in (u or '')]\n",
    "                            website = (ext[0] if ext else (urls[0] if urls else None)) or None\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                # If opened, try to find URL from modal\n",
    "                if opened and website is None:\n",
    "                    try:\n",
    "                        await page.wait_for_selector('[role=\"dialog\"], .modal, .modal-dialog, .modal-content, .MuiDialog-root, .chakra-modal__content', timeout=MODAL_TIMEOUT)\n",
    "                        modal = page.locator('[role=\"dialog\"], .modal, .modal-dialog, .modal-content, .MuiDialog-root, .chakra-modal__content').last\n",
    "                        # Try common variants of 'Visit Website' labelling\n",
    "                        btn = None\n",
    "                        for cand in [\n",
    "                            modal.get_by_role('link', name=re.compile('Visit Website|Website|Web site|Company website|Open website|Go to website', re.I)),\n",
    "                            modal.get_by_role('button', name=re.compile('Visit Website|Website|Web site|Company website|Open website|Go to website', re.I)),\n",
    "                            modal.get_by_text(re.compile('Visit Website|Website|Web site|Company website|Open website|Go to website', re.I)),\n",
    "                        ]:\n",
    "                            try:\n",
    "                                if await cand.count() > 0:\n",
    "                                    btn = cand.first\n",
    "                                    break\n",
    "                            except Exception:\n",
    "                                continue\n",
    "                        # 1) Try attribute href on the control if it's a link\n",
    "                        if btn and website is None:\n",
    "                            try:\n",
    "                                href = await btn.get_attribute('href')\n",
    "                                if href:\n",
    "                                    website = href\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                        # 2) If there is any external-looking link in the modal, use it\n",
    "                        if website is None:\n",
    "                            try:\n",
    "                                link_locator = modal.locator('a[href^=\"http\"]')\n",
    "                                if await link_locator.count() > 0:\n",
    "                                    # Prefer external (non-ntpns) link first\n",
    "                                    urls = []\n",
    "                                    for i in range(min(5, await link_locator.count())):\n",
    "                                        href = await link_locator.nth(i).get_attribute('href')\n",
    "                                        if href:\n",
    "                                            urls.append(href)\n",
    "                                    ext = [u for u in urls if 'ntpns.rs' not in (u or '')]\n",
    "                                    website = (ext[0] if ext else (urls[0] if urls else None)) or None\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                        # 3) Look into data-* and onclick within modal, and text URLs\n",
    "                        if website is None:\n",
    "                            try:\n",
    "                                urls = await modal.evaluate(\"\"\"(root)=>{\n",
    "                                    const urls=new Set();\n",
    "                                    const add=u=>{ if(u && /^https?:\\/\\//i.test(u)) urls.add(u); };\n",
    "                                    root.querySelectorAll('[data-href]').forEach(el=>add(el.getAttribute('data-href')));\n",
    "                                    root.querySelectorAll('[onclick]').forEach(el=>{\n",
    "                                        const oc = el.getAttribute('onclick')||'';\n",
    "                                        const m = oc.match(/https?:\\/\\/[^'\\\"\\s)]+/ig);\n",
    "                                        if(m) m.forEach(add);\n",
    "                                    });\n",
    "                                    const txt = root.innerText||'';\n",
    "                                    const mtxt = txt.match(/https?:\\/\\/[^\\s]+/ig);\n",
    "                                    if(mtxt) mtxt.forEach(add);\n",
    "                                    return Array.from(urls);\n",
    "                                }\"\"\")\n",
    "                                ext = [u for u in urls if 'ntpns.rs' not in (u or '')]\n",
    "                                website = (ext[0] if ext else (urls[0] if urls else None)) or None\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                        # 4) If still missing and we have a control, click and catch popup URL\n",
    "                        if btn and website is None:\n",
    "                            try:\n",
    "                                async with page.expect_popup(timeout=1500) as pop_info:\n",
    "                                    await btn.click()\n",
    "                                popup = await pop_info.value\n",
    "                                website = popup.url\n",
    "                                await popup.close()\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                        # 5) As a last resort, attempt navigation capture and go back\n",
    "                        if btn and website is None:\n",
    "                            try:\n",
    "                                prev_url = page.url\n",
    "                                async with page.expect_navigation(timeout=1500):\n",
    "                                    await btn.click()\n",
    "                                website = page.url if page.url != prev_url else None\n",
    "                                await page.go_back(timeout=PAGE_TIMEOUT)\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                        # Close modal (best-effort)\n",
    "                        closed = False\n",
    "                        for close_candidate in [\n",
    "                            modal.get_by_role('button', name=re.compile('Close|×|✕|X', re.I)),\n",
    "                            page.get_by_role('button', name=re.compile('Close|×|✕|X', re.I)),\n",
    "                        ]:\n",
    "                            try:\n",
    "                                await close_candidate.first.click(timeout=800)\n",
    "                                closed = True\n",
    "                                break\n",
    "                            except Exception:\n",
    "                                continue\n",
    "                        if not closed:\n",
    "                            try:\n",
    "                                await page.keyboard.press('Escape')\n",
    "                            except Exception:\n",
    "                                try:\n",
    "                                    await page.mouse.click(10, 10)\n",
    "                                except Exception:\n",
    "                                    pass\n",
    "                    except Exception:\n",
    "                        # modal did not appear in time; proceed without website\n",
    "                        pass\n",
    "                # ALWAYS record the row even if modal/website not found\n",
    "                rows.append({'name': name, 'website': website or '', 'category': cat})\n",
    "        await browser.close()\n",
    "    return rows\n",
    "\n",
    "# Run (with a bounded total time by relying on small timeouts)\n",
    "rows = asyncio.get_event_loop().run_until_complete(scrape_ntpns_async())\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2629005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 59 rows to /home/thiesen/Documents/AI-Innoscence_Ecosystem/Input/Novi Sad/ntpns_members.csv\n",
      "Websites found: 0 / 59\n"
     ]
    }
   ],
   "source": [
    "# Clean and save\n",
    "def clean_rows(rows):\n",
    "    out = []\n",
    "    seen = set()\n",
    "    for r in rows:\n",
    "        name = re.sub(r'\\s+', ' ', (r.get('name') or '').strip())\n",
    "        site = (r.get('website') or '').strip()\n",
    "        cat = r.get('category') or ''\n",
    "        if not name:\n",
    "            continue\n",
    "        key = (name.lower(), site.lower(), cat)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append({'name': name, 'website': site, 'category': cat})\n",
    "    return out\n",
    "\n",
    "clean = clean_rows(rows)\n",
    "df = pd.DataFrame(clean)\n",
    "output_path = Path('/home/thiesen/Documents/AI-Innoscence_Ecosystem/Input/Novi Sad/ntpns_members.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "non_empty = (df['website'].str.len() > 0).sum() if not df.empty else 0\n",
    "print(f'Saved {len(df)} rows to {output_path}')\n",
    "print(f'Websites found: {non_empty} / {len(df)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Innoscence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
