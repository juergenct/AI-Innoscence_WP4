{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ca56b0",
   "metadata": {},
   "source": [
    "# Startap Portal Serbia â€” Organizations extraction\n",
    "\n",
    "Goal: Scrape https://startap.gov.rs/en/organizations/ and produce a CSV with columns: group, name, website, domain, source.\n",
    "\n",
    "Approach:\n",
    "- Try a fast static parse (requests + BeautifulSoup).\n",
    "- If static returns 0, fallback to a browser approach (Playwright) to extract all cards including any lazy-loaded content.\n",
    "\n",
    "Output file: `Input/Novi Sad/startap_portal_serbia_organizations.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf9859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiesen/.conda/envs/AI_Innoscence/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports and helpers\n",
    "from __future__ import annotations\n",
    "import re\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, urljoin\n",
    "import os\n",
    "import sys\n",
    "\n",
    "SOURCE_URL = \"https://startap.gov.rs/en/organizations/\"\n",
    "notebook_dir = os.path.abspath(\".\")  # use current notebook folder\n",
    "output_path = os.path.join(notebook_dir, \"startap_portal_serbia_organizations.csv\")\n",
    "\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121 Safari/537.36\",\n",
    "})\n",
    "\n",
    "def fetch_html(url: str, retries: int = 2, timeout: int = 30) -> Optional[str]:\n",
    "    for i in range(retries + 1):\n",
    "        try:\n",
    "            r = SESSION.get(url, timeout=timeout)\n",
    "            if r.status_code == 200:\n",
    "                return r.text\n",
    "        except Exception:\n",
    "            time.sleep(1 + i)\n",
    "    return None\n",
    "\n",
    "def get_soup(url: str) -> Optional[BeautifulSoup]:\n",
    "    html = fetch_html(url)\n",
    "    if not html:\n",
    "        return None\n",
    "    return BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "def canonicalize_url(base: str, href: str) -> Optional[str]:\n",
    "    if not href:\n",
    "        return None\n",
    "    href = href.strip()\n",
    "    if href.startswith((\"mailto:\", \"tel:\")):\n",
    "        return None\n",
    "    return urljoin(base, href)\n",
    "\n",
    "def extract_domain(u: str) -> str:\n",
    "    try:\n",
    "        host = urlparse(u).netloc.lower()\n",
    "        return host[4:] if host.startswith(\"www.\") else host\n",
    "    except Exception:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb0df88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static parse: found 46 rows\n",
      "Wrote /home/thiesen/Documents/AI-Innoscence_Ecosystem/Input/startap_portal_serbia_organizations.csv\n"
     ]
    }
   ],
   "source": [
    "# Static scraper\n",
    "def parse_startap_static(url: str = SOURCE_URL) -> List[Dict]:\n",
    "    soup = get_soup(url)\n",
    "    if not soup:\n",
    "        print(\"Static: failed to load HTML\")\n",
    "        return []\n",
    "\n",
    "    rows: List[Dict] = []\n",
    "    # Strategy: find anchors whose text includes 'Visit website' and pair with a nearby title within the same card.\n",
    "    anchors = []\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        txt = (a.get_text(\" \") or \"\").strip().lower()\n",
    "        if \"visit website\" in txt:\n",
    "            anchors.append(a)\n",
    "\n",
    "    def find_title(node) -> Optional[str]:\n",
    "        # Search within the same card for a title\n",
    "        # climb up to a container with 'card' or 'organization' in class, then look for h3/h2/a strong text\n",
    "        cur = node\n",
    "        for _ in range(5):\n",
    "            if not cur:\n",
    "                break\n",
    "            classes = \" \".join(cur.get(\"class\", [])) if hasattr(cur, 'get') and cur.has_attr(\"class\") else \"\"\n",
    "            if any(tok in classes.lower() for tok in [\"card\", \"organization\", \"org\", \"item\", \"entry\"]):\n",
    "                # within this, search for a likely title\n",
    "                for sel in [\"h3\", \"h2\", \"a\", \"strong\"]:\n",
    "                    h = cur.select_one(sel)\n",
    "                    if h and (h.get_text(strip=True) or \"\").strip():\n",
    "                        return h.get_text(strip=True)\n",
    "            cur = cur.parent\n",
    "        # fallback: siblings upwards\n",
    "        cur = node\n",
    "        for _ in range(3):\n",
    "            if not cur:\n",
    "                break\n",
    "            sib = cur.find_previous([\"h3\",\"h2\"])\n",
    "            if sib and sib.get_text(strip=True):\n",
    "                return sib.get_text(strip=True)\n",
    "            cur = cur.parent\n",
    "        return None\n",
    "\n",
    "    for a in anchors:\n",
    "        href = canonicalize_url(url, a.get(\"href\"))\n",
    "        if not href:\n",
    "            continue\n",
    "        name = find_title(a) or \"\"\n",
    "        rows.append({\n",
    "            \"group\": \"organizations\",\n",
    "            \"name\": name,\n",
    "            \"website\": href,\n",
    "            \"domain\": extract_domain(href),\n",
    "            \"source\": SOURCE_URL,\n",
    "        })\n",
    "\n",
    "    # Dedupe by domain\n",
    "    seen = set()\n",
    "    dedup = []\n",
    "    for r in rows:\n",
    "        key = r[\"domain\"]\n",
    "        if not key or key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        dedup.append(r)\n",
    "\n",
    "    print(f\"Static parse: found {len(dedup)} rows\")\n",
    "    return dedup\n",
    "\n",
    "static_rows = parse_startap_static()\n",
    "if static_rows:\n",
    "    pd.DataFrame(static_rows).to_csv(output_path, index=False)\n",
    "    print(f\"Wrote {output_path}\")\n",
    "else:\n",
    "    print(\"Static returned 0; you can run the Playwright fallback cell next.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aee025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playwright fallback (handles dynamic loading if any)\n",
    "import asyncio\n",
    "\n",
    "async def scrape_startap_playwright(headless: bool = True) -> List[Dict]:\n",
    "    try:\n",
    "        from playwright.async_api import async_playwright\n",
    "    except Exception as e:\n",
    "        print(\"Playwright not available in this kernel.\")\n",
    "        return []\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=headless, args=[\"--no-sandbox\", \"--disable-dev-shm-usage\"])\\\n",
    "\n",
    "        ctx = await browser.new_context()\n",
    "        page = await ctx.new_page()\n",
    "        await page.goto(SOURCE_URL, wait_until=\"domcontentloaded\", timeout=60000)\n",
    "\n",
    "        # Accept cookies if banner exists\n",
    "        for sel in [\"button:has-text('Accept')\", \"#cn-accept-cookie\", \"button[aria-label='Accept']\", \"//button[contains(., 'Accept')]\"]:\n",
    "            try:\n",
    "                await page.locator(sel).first.click(timeout=2000)\n",
    "                break\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Wait for cards to appear\n",
    "        try:\n",
    "            await page.locator(\"a:has-text('Visit website')\").first.wait_for(timeout=8000)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Scroll to bottom to ensure all items are rendered\n",
    "        try:\n",
    "            prev = 0\n",
    "            for _ in range(12):\n",
    "                await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "                await page.wait_for_timeout(600)\n",
    "                cur = await page.evaluate(\"document.body.scrollHeight\")\n",
    "                if cur == prev:\n",
    "                    break\n",
    "                prev = cur\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        data = await page.evaluate(\"\"\"\n",
    "() => {\n",
    "  const items = [];\n",
    "  const anchors = Array.from(document.querySelectorAll(\"a[href]\"))\n",
    "    .filter(a => (a.textContent || '').toLowerCase().includes('visit website'));\n",
    "\n",
    "  const titleFor = (a) => {\n",
    "    let cur = a;\n",
    "    for (let i = 0; i < 6 && cur; i++) {\n",
    "      cur = cur.parentElement;\n",
    "      if (!cur) break;\n",
    "      const cls = (cur.getAttribute('class') || '').toLowerCase();\n",
    "      if (/(card|organization|org|item|entry)/.test(cls)) {\n",
    "        const t = cur.querySelector('h3, h2, a, strong');\n",
    "        if (t && (t.textContent || '').trim()) return t.textContent.trim();\n",
    "      }\n",
    "    }\n",
    "    // Fallback: look for closest preceding heading\n",
    "    let node = a;\n",
    "    for (let i = 0; i < 3 && node; i++) {\n",
    "      const prev = node.previousElementSibling;\n",
    "      if (prev && /H[23]/.test(prev.tagName) && (prev.textContent || '').trim()) return prev.textContent.trim();\n",
    "      node = node.parentElement;\n",
    "    }\n",
    "    return '';\n",
    "  };\n",
    "\n",
    "  for (const a of anchors) {\n",
    "    const href = a.href;\n",
    "    if (!href || href.startsWith('mailto:') || href.startsWith('tel:')) continue;\n",
    "    items.push({ name: titleFor(a), website: href });\n",
    "  }\n",
    "  return items;\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "        # Normalize & dedupe\n",
    "        rows: List[Dict] = []\n",
    "        for rec in data:\n",
    "            href = rec.get(\"website\")\n",
    "            if not href:\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"group\": \"organizations\",\n",
    "                \"name\": (rec.get(\"name\") or \"\").strip(),\n",
    "                \"website\": href,\n",
    "                \"domain\": extract_domain(href),\n",
    "                \"source\": SOURCE_URL,\n",
    "            })\n",
    "\n",
    "        seen = set()\n",
    "        dedup = []\n",
    "        for r in rows:\n",
    "            if not r[\"domain\"] or r[\"domain\"] in seen:\n",
    "                continue\n",
    "            seen.add(r[\"domain\"])\n",
    "            dedup.append(r)\n",
    "        return dedup\n",
    "\n",
    "# Execute fallback if static_rows empty\n",
    "fallback_rows: List[Dict] = []\n",
    "if not static_rows:\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "    except RuntimeError:\n",
    "        import nest_asyncio, asyncio as _asyncio\n",
    "        nest_asyncio.apply()\n",
    "        loop = _asyncio.get_event_loop()\n",
    "    fallback_rows = loop.run_until_complete(scrape_startap_playwright(headless=True))\n",
    "    print(f\"Playwright fallback: found {len(fallback_rows)} rows\")\n",
    "    if fallback_rows:\n",
    "        pd.DataFrame(fallback_rows).to_csv(output_path, index=False)\n",
    "        print(f\"Wrote {output_path}\")\n",
    "    else:\n",
    "        print(\"No rows found via fallback. You can try setting headless=False inside scrape_startap_playwright().\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9977cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previewing: /home/thiesen/Documents/AI-Innoscence_Ecosystem/Input/startap_portal_serbia_organizations.csv\n",
      "(46, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>name</th>\n",
       "      <th>website</th>\n",
       "      <th>domain</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>organizations</td>\n",
       "      <td>Founder Institute Srbija</td>\n",
       "      <td>https://fi.co/</td>\n",
       "      <td>fi.co</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>organizations</td>\n",
       "      <td>GameBiz Consulting</td>\n",
       "      <td>https://www.gamebizconsulting.com/</td>\n",
       "      <td>gamebizconsulting.com</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>organizations</td>\n",
       "      <td>Haos Community Space</td>\n",
       "      <td>https://www.haos.space/</td>\n",
       "      <td>haos.space</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>organizations</td>\n",
       "      <td>ICT Hub</td>\n",
       "      <td>https://www.icthub.rs/</td>\n",
       "      <td>icthub.rs</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>organizations</td>\n",
       "      <td>ICT Hub Venture</td>\n",
       "      <td>https://icthubventure.com/en/</td>\n",
       "      <td>icthubventure.com</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>organizations</td>\n",
       "      <td>Impact Hub</td>\n",
       "      <td>https://belgrade.impacthub.net/</td>\n",
       "      <td>belgrade.impacthub.net</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>organizations</td>\n",
       "      <td>InspiraHub</td>\n",
       "      <td>https://www.inspirahub.rs/</td>\n",
       "      <td>inspirahub.rs</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>organizations</td>\n",
       "      <td>IVM Coworking Loznica</td>\n",
       "      <td>https://ivmcoworking.com</td>\n",
       "      <td>ivmcoworking.com</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>organizations</td>\n",
       "      <td>Loud Crowd</td>\n",
       "      <td>https://loudcrowd.rs/</td>\n",
       "      <td>loudcrowd.rs</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>organizations</td>\n",
       "      <td>Mini Hub Workspace</td>\n",
       "      <td>https://coworkingsmederevo.rs/</td>\n",
       "      <td>coworkingsmederevo.rs</td>\n",
       "      <td>https://startap.gov.rs/en/organizations/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           group                      name  \\\n",
       "0  organizations  Founder Institute Srbija   \n",
       "1  organizations        GameBiz Consulting   \n",
       "2  organizations      Haos Community Space   \n",
       "3  organizations                   ICT Hub   \n",
       "4  organizations           ICT Hub Venture   \n",
       "5  organizations                Impact Hub   \n",
       "6  organizations                InspiraHub   \n",
       "7  organizations     IVM Coworking Loznica   \n",
       "8  organizations                Loud Crowd   \n",
       "9  organizations        Mini Hub Workspace   \n",
       "\n",
       "                              website                  domain  \\\n",
       "0                      https://fi.co/                   fi.co   \n",
       "1  https://www.gamebizconsulting.com/   gamebizconsulting.com   \n",
       "2             https://www.haos.space/              haos.space   \n",
       "3              https://www.icthub.rs/               icthub.rs   \n",
       "4       https://icthubventure.com/en/       icthubventure.com   \n",
       "5     https://belgrade.impacthub.net/  belgrade.impacthub.net   \n",
       "6          https://www.inspirahub.rs/           inspirahub.rs   \n",
       "7            https://ivmcoworking.com        ivmcoworking.com   \n",
       "8               https://loudcrowd.rs/            loudcrowd.rs   \n",
       "9      https://coworkingsmederevo.rs/   coworkingsmederevo.rs   \n",
       "\n",
       "                                     source  \n",
       "0  https://startap.gov.rs/en/organizations/  \n",
       "1  https://startap.gov.rs/en/organizations/  \n",
       "2  https://startap.gov.rs/en/organizations/  \n",
       "3  https://startap.gov.rs/en/organizations/  \n",
       "4  https://startap.gov.rs/en/organizations/  \n",
       "5  https://startap.gov.rs/en/organizations/  \n",
       "6  https://startap.gov.rs/en/organizations/  \n",
       "7  https://startap.gov.rs/en/organizations/  \n",
       "8  https://startap.gov.rs/en/organizations/  \n",
       "9  https://startap.gov.rs/en/organizations/  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview a few lines if file exists\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "candidates = [\n",
    "    output_path,\n",
    "    str(Path(os.getcwd())/\"startap_portal_serbia_organizations.csv\"),\n",
    "    \"/home/thiesen/Documents/AI-Innoscence_Ecosystem/Input/Novi Sad/startap_portal_serbia_organizations.csv\",\n",
    "]\n",
    "\n",
    "found = None\n",
    "for p in candidates:\n",
    "    if os.path.exists(p):\n",
    "        found = p\n",
    "        break\n",
    "\n",
    "if found:\n",
    "    print(f\"Previewing: {found}\")\n",
    "    df = pd.read_csv(found)\n",
    "    print(df.shape)\n",
    "    display(df.head(10))\n",
    "else:\n",
    "    print(\"Output file not found yet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Innoscence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
